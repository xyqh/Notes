# 操作系统

## 基础相关

### 文件描述符

> file descriptor，简称fd。Linux系统中，把一切都看作是文件，当进程打开现有文件或者创建新文件时，内核向进程返回一个文件描述符，文件描述符就是内核为了高效管理已被打开的文件所创建的索引，用来指向被打开的文件，所有执行I/O操作的系统调用都会通过文件描述符。
>
> 系统为每一个进程维护了一个文件描述表，表示该进程打开文件的记录表，而文件描述符实际上就是这张表的索引。当进程打开或者新建文件时，内核会在该进程的文件列表中新增一个表项，同时返回一个文件描述符，也就是新增表项的下标。
>
> 一般来说，每个进程最多可以打开64个文件，fd∈[0,63]。在不同系统上，最多允许打开的文件个数不同，Linux2.4.22强制规定最多不能超过1,048,576。
>
> 每个进程默认都有3个文件描述符：0(stdin)、1(stdout)、2(stderr)。

### 套接字（socket）和文件描述符（fd）的关系

> socket是Unix中的术语。socket可以用于同一台主机的不同进程间的通信，也可以用于不同主机间的通信。一个socket包含地址、类型和通信协议等信息，通过socket()函数创建：
>
> ```c++
> int socket(int domain, int type, int protocol)
> ```
>
> 返回的就是这个socket对应的文件描述符fd。操作系统将socket映射到进程的一个文件描述符上，进程就可以通过读写这个文件描述符来和远程主机通信。

### 内核态和用户态

> 为了限制不同程序的访问能力，防止一些程序访问其他程序的内部数据，CPU划分了内核态和用户态两个权限等级。
>
> - 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换
> - 用户态只能受限地访问内存，且不允许访问外围设备，占有占用CPU的能力，CPU资源可以被其他成或许获取
>
> 所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用陷阱指令，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。

### 如何从用户态切换到内核态

> 1. 系统调用，比如读取命令行输入，本质上还是通过中断实现
> 2. 异常，用户程序发生异常，比如缺页异常
> 3. 外中断，外围设备的中断，外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理相应的中断处理程序

### 临界资源、临界代码、临界区

> 1. 多个进程或线程有可能同时访问的资源（变量、链表、文件等）称为共享资源，也叫临界资源
> 2. 访问这些资源的代码称为临界代码，这些代码区域称为临界区
> 3. 程序进入临界区之前必须要对资源进行申请，这个动作称为P操作
> 4. 程序离开临界区之后必须要释放相应的资源，这个动作被称为V操作

### 并发、并行、异步的区别

> **并发**：在一个时间段中有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的
>
> **并行**：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的
>
> **异步**：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事

### 什么是程序计数器

> [程序计数器](https://www.baidu.com/s?wd=程序计数器&usm=1&ie=utf-8&rsv_pq=ebf01741003ce562&oq=什么是程序计数器&rsv_t=7d0dt%2FAlUwukVa8QLJXnWNbg9ze1lIw95yHpMPowXuy0f5yg%2BdWbtn6c6Ow&sa=re_dqa_zy&icon=1)(Program Counter)是一种特殊的寄存器，用于存储当前线程正在执行的指令的地址或下一条要执行的指令的地址





## 进程

### 进程与线程和协程的区别和联系

> |          | 进程                                                         | 线程                                                 | 协程                                                         |
> | -------- | ------------------------------------------------------------ | ---------------------------------------------------- | ------------------------------------------------------------ |
> | 定义     | 资源分配和调度的基本单位                                     | 程序执行的基本单位                                   | 用户态的轻量级线程，线程内部调度的基本单位                   |
> | 切换情况 | 进程CPU环境（栈、寄存器、页表、文件句柄等）的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容           | 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复         |
> | 切换者   | 操作系统                                                     | 操作系统                                             | 用户                                                         |
> | 切换过程 | 用户态->内核态->用户态                                       | 用户态->内核态->用户态                               | 用户态（没有进入内核态）                                     |
> | 调用栈   | 内核栈                                                       | 内核栈                                               | 用户栈                                                       |
> | 拥有资源 | CPU资源、内存资源、文件资源和句柄等                          | 程序计数器、寄存器、栈和状态字                       | 拥有自己的寄存器上下文和栈                                   |
> | 并发性   | 不同进程之间切换实现并发                                     | 一个进程内部的多个线程并发执行                       | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
> | 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 | 切换时只需要保存和设置少量寄存器内容，因此开销很小   | 直接操作栈则基本没有内核切换的开销，可以不加锁地访问全局变量，所以上下文的切换非常快 |
> | 通信方面 | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段（如全局变量）来进行通信 | 共享内存、消息队列                                           |
>
> 1. 进程是资源调度的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序。
> 2. 线程是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。
> 3. 协程是用户态的轻量级线程，线程内部调度的基本单位。

### 相比进程，线程的优势

> 1. 线程启动速度快，轻量级
> 2. 线程的系统开销小
> 3. 线程使用有一定难度，需要处理数据一致性问题
> 4. 同一线程共享的有堆、全局变量、静态变量、指针、引用、文件等，而独自占有栈

### 一个进程可以创建多少线程

> 一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定，只要虚拟空间足够，那么新线程的建立就会成功。

### 同一进程中的线程可以共享哪些数据

> - 进程代码段
> - 进程的公有数据（全局变量、静态变量...）
> - 进程打开的文件描述符
> - 进程的当前目录
> - 信号处理器/信号处理函数：对收到的信号的处理方式
> - 进程ID与进程组ID

### 线程独占哪些资源

> - 线程ID
> - 一组寄存器的值
> - 线程自身的栈（堆是共享的）
> - 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改
> - 信号掩码/信号屏蔽字：表示是否屏蔽/阻塞相应的信号（SIGKILL，SIGSTOP除外）

### 线程同步有哪些方式

> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。
>
> - **互斥量Mutex**：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权现。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源。
> - **信号量Semaphore**：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过ReleaseSemephore函数将当前可用资源数加1.如果信号量的取址只能为0或1，那就退化成了互斥量。
> - **事件Event**：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为**手动重置事件**和**自动重置事件**。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。
> - **临界区Critical Section**：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其他试图访问该资源的线程将被挂起，直到临界区对象被释放。

### 互斥量和临界区的区别

> 互斥量是可以命名的，可以用于不同进程之间的同步。而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。

### 进程间通信（IPC）

> | 方式     | 传输的数据量       | 使用场景       | 关键词                                                       |
> | -------- | ------------------ | -------------- | ------------------------------------------------------------ |
> | 信号     | 少量               | 任何           | 硬件来源、软件来源、信号队列                                 |
> | 管道     | 大量               | 亲缘进程间     | 单向流动、内核缓冲区、循环队列、没有格式的字节流、操作系统负责同步 |
> | 命名管道 | 大量               | 任何           | 磁盘文件、访问权限、无数据块、内核缓冲区、操作系统负责同步   |
> | 信号量   | N                  | 任何           | 互斥同步、原子性、P减V增                                     |
> | 共享内存 | 大量               | 多个进程       | 内存映射、简单快速、操作系统不保证同步                       |
> | 消息队列 | 比信号多，但有限制 | 任何           | 有格式、按消息类型过滤、操作系统负责同步                     |
> | 套接字   | 大量               | 不同主机的进程 | 读缓存区、写缓存区、操作系统负责同步                         |
>
> #### 信号（Signal）
>
> > - 信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态
> > - ~~如果该进程当前并未处于执行状态，则该状态就由内核保存起来，直到该进程恢复执行并传递给它为止~~ **存疑**
> > - 如果一个信号被进程设置为阻塞，则该信号的传递被延迟，知道其阻塞被取消时才被传递给该进程
> >
> > ##### 信号来源
> >
> > 信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号主要有两个来源：
> >
> > - 硬件来源：用户案件输入**Ctrl+C**退出、硬件异常如无效的存储访问等
> > - 软件终止：终止进程信号、其他进程调用kill函数、软件异常产生信号
> >
> > ##### 信号声明周期和处理流程
> >
> > 1. 信号被某个进程产生，并设置此信号的传递对象（一般为对应进程的pid），然后传递给操作系统。
> > 2. 操作系统根据此接收进程的设置（是否阻塞此信号）而选择性地发送给接收者，如果该接收者阻塞该信号（且该信号是可以被阻塞的），操作系统将暂时保留该信号而不传递，直到该进程解除了对此信号的阻塞（如果对应进程已经退出，则丢弃此信号），如果对应进程没有阻塞，操作系统将传递此信号。
> > 3. 目的进程接收到此信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（主要包括临时寄存器数据，当前程序位置以及当前CPU的状态）、转而执行中断服务程序，执行完成后再恢复到中断的位置。当然，对于抢占式内核，在中断返回时还将引发新的调度。
>
> #### 管道（匿名管道PIPE）
>
> > - 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。
> > - 只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。
> > - 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于文件系统，而是自立门户，单独构成一种文件系统，并且只存在于内存中。
> > - 数据的读出和写入：一个进程向通道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。
> >
> > ##### 管道的实质：
> >
> > - 管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序地将数据写入缓冲区，另一端的进程则顺序地读出数据。
> > - 该缓冲区可以看作是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。
> > - 当缓冲区读空或者写满时，有一定的规则控制读进程和写进程进入等待队列，当空的缓冲区有数据写入或者满的缓冲区有数据读出时，就会唤醒等待队列中的进程继续读写。
> > - 写进程或者读进程需要等另一方释放锁后才能操作管道，同一时间只能有一个进程访问
> > - 管道不再被任何进程使用时，自动消失
> >
> > ##### 管道的局限：
> >
> > - 只支持单向数据流
> > - 只能用于具有亲缘关系的进程
> > - 没有名字
> > - 缓冲区的大小是有限的，管道只存在于内存中，在管道创建时，为缓冲区分配一个页面大小
> > - 数据是无格式的字节流，需要发送方和接收方事先约定好数据的格式，例如多少个字节是一个消息或命令
> > - 匿名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出，如果管道发现另一端断开，将自动退出
>
> #### 命名管道（FIFO）
>
> > 匿名管道只能用于亲缘关系之间的进程通信，为了克服这一缺点，提出了命名管道。
> >
> > 不同于匿名管道的是，命名管道提供了一个路径名与之关联，以命名管道的文件形式存在于文件系统中，这样，即使与命名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过命名管道相互通信。命名管道严格遵循先进先出（FIFO），对读操作总是从开始处返回数据，写操作总是把数据添加到末尾，不支持如ISeek()等文件定位操作。命名管道的名字存在于文件系统中，内容存放在内存中。
> >
> > 命名管道在打开时需要确认对方的存在，否则将阻塞。此外可以以读写（O_RDWR）模式打开命名管道，即当前进程读当前进程写，不会阻塞。
>
> #### 消息队列
>
> > - 消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符标识
> > - 与管道不同的是，消息队列只有在内核重启（即操作系统重启）或者显式删除一个消息队列时才会被真正删除
> > - 进程在向消息队列写入数据时，不需要有进程该消息队列上等待信息的到来
> >
> > 消息队列特点：
> >
> > - 是消息的链表，具有特定的格式，存在于内存中由消息队列标识符标识
> > - 允许一个或多个进程对消息队列进行读写
> > - 遵循先进先出
> > - 可以实现消息类型的随即查询，不一定要以先进先出的次序读取，也可以按照消息类型进行读取
> > - 克服了信号承载消息量少，管道只能承载无格式化字节流以及缓冲区大小受限等缺点
> > - 主要分为两种：POSIX消息队列和System V消息队列，其中V消息队列只有当内核重启或者显式删除时才会被真正删除
>
> #### 共享内存
>
> > - 使得多个进程可以直接读写同一块的内存区域，是最快的可用IPC形式。是针对其他进程通信机制允许效率较低设计的
> > - 为了在多个进程之间同步信息，内核专门留出了一块内存区，可以由需要访问的进程映射到自己的私有地址空间，而不需要进行数据拷贝直接进行读写，从而大大提高效率
> > - 由于多个进程共享一块内存，需要依靠某种同步机制（如信号量），来达到进程间的同步与互斥
>
> #### 信号量（semaphore）
>
> > 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间的同步。一般表示资源的数量。一般是一个数组。
> >
> > 1. **创建一个信号量**：这要求调用者指定初始值，对于二值信号量（在Linux中，又称互斥锁Mutex）来说，它通常是1，也可以是0.
> > 2. **等待一个信号量**：该操作会测试这个信号量的值，如果小于0，就阻塞，否则减1，也称为**P**操作。
> > 3. **挂出一个信号量**：该操作将信号量的值加1，也称为**V**操作。
> >
> > Linux中，信号量的三种类型：
> >
> > 1. Posix（可移植性操作系统接口）有名信号量，使用Posix IPC名字标识
> > 2. Posix基于内存的信号量，存放在共享内存区中
> > 3. System V信号量，在内核中维护
>
> #### 套接字（Socket）
>
> > 套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接的计算机上的进程进行通信。
> >
> > 套接字是支持TCP/IP的网络通信的基本单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的双方的一种约定，用套接字中的相关函数来完成通信过程。
> >
> > ###### 套接字特性：域、端口号、协议类型
> >
> > ###### 1. 域：指套接字通信中使用的网络介质，最常见的有两种
> >
> > > 1. AF_INET，指Internet网络。当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。
> > > 2. AF_UNIX，指UNIX文件系统。它就是文件输入/输出，而它的地址就是文件名。
> >
> > ###### 2. 套接字的端口号
> >
> > > 每一个基于TCP/IP网络通讯的程序（进程）都被赋予了唯一的端口和端口号，端口是一个信息缓冲区，用于保留socket中的输入/输出信息，端口号是一个16位无符号整数，范围是0-65535，以区别主机上的每一个程序，低于256的端口号保留给标准应用程序，比如pop3的端口号就是110，每一个套接字都组合进了IP地址、端口，这样形成的整体就可以区别每一个套接字。
> >
> > ###### 3. 套接字协议类型
> >
> > > 1. 流套接字，TCP协议
> > > 2. 数据包套接字，UDP协议
> > > 3. 原始套接字，原始套接字允许对较低层次的协议直接访问，比如IP、ICMP协议，它常用于校验新的协议实现，或者访问现有服务中配置的新设备，因为RAW SOCKET可以自如地控制Windows下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操作网络层和传输层应用。比如，我们可以通过RAW SOCKET来接收发向本机的ICMP、IGMP协议包，或者接收TCP/IP栈不能处理的IP包，也可以用来发送一些自定包头或者自定协议的IP包。网络监听技术很大程度上依赖于SOCKET_RAW。
> > >
> > > 原始套接字可以读写内核没有处理的IP数据包。如果要访问其他协议发送数据必须使用原始套接字。
> >
> > ##### 套接字通信的建立
> >
> > > 一个socket是可以建立多个TCP连接的。
> > >
> > > **服务端：**
> > >
> > > 1. 服务端应用程序用系统调用socket来创建一个套接字，它是系统分配给服务器进程的类似文件描述符的资源，不能与其他的进程共享。
> > > 2. 进程会给套接字起名字，使用系统调用bind来给套接字命名，然后服务器进程就开始等待客户端连接到这个套接字
> > > 3. 系统调用listen来创建一个队列并将其用于存放来自客户端的进入连接
> > > 4. 服务器通过系统调用accept来接收客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（原先的套接字）则被保留下来继续处理来自其他客户的连接（建立客户端和服务端的用于通信的流，进行通信）。
> > >
> > > **客户端**
> > >
> > > 1. 客户端应用程序首先调用socket来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用connect与服务器建立连接
> > > 2. 一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信（通过流进行数据传输）。

### 孤儿进程和僵尸进程

> 在Linux环境中，我们是通过`fork`函数来创建子进程的。创建完毕之后，父子进程独立运行，父进程无法预知子进程什么时候结束。
>
> 通常情况下，子进程退出后，父进程会使用`wait/waitpid`函数回收子进程的资源，并获得子进程的终止状态。
>
> UNIX提供了一种机制，可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。
>
> > 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留了**一定的信息（包括进程号、退出状态、运行时间等）**。直到父进程通过`wait/waitpid`来取时才释放。
>
> **孤儿进程**：如果父进程先于子进程结束，则子进程成为孤儿进程。孤儿进程将被`init`进程（进程号为1）领养，并由`init`进程对孤儿进程完成状态收集工作。
>
> **僵尸进程**：如果子进程先于父进程退出，同时父进程太忙了，无暇回收子进程的资源，子进程残留资源（PCB）存放于内核中，变成僵尸进程。

### 写时复制Copy-on-write，COW

> 写时复制（Copy-on-write，COW），有时也成为隐式共享（implicit sharing）。COW将复制操作推迟到第一次写入时进行：在创建一个新副本时，不会立刻复制资源，而是共享原始副本的资源；当修改时再执行复制操作，通过这种方式共享资源，可以显著减少创建副本时的开销，以及节省资源。同时，资源修改操作会增加少量开销。

### 为什么需要COW？

> 当通过fork()来创建一个子进程时，操作系统需要将父进程虚拟内存空间中的大部分内容全部复制到子进程中（主要是数据段、堆、栈；代码段共享）。这个操作不仅非常耗时，而且会浪费大量物理内存。特别是如果程序在进程复制后立刻使用exec加载新程序，那么负面效应会更严重，相当于之前进行的复制操作完全是多余的。
>
> 因此引入了写时复制技术。内核不会复制进程的整个地址空间，而是只复制其页表，fork之后的父子进程的地址空间指向同样的物理内存页。
>
> 但是不同进程的内存空间应当是私有的。假如所有进程都只读取其内存页，那么就可以继续共享物理内存中的同一个副本；然而只要有一个进程试图写入共享区域的某个页面，那么就会为这个进程创建该页面的一个新副本。
>
> 写时复制技术将内存页的复制延迟到第一次写入时，更重要的是，在很多情况下不需要复制。这节省了大量时间，充分使用了稀有的物理内存。

### COW的实现原理

> fork()之后，内核会把父进程的所有内存页都标记为只读（即使是原始进程也要重新复制，只有最后一个想要修改这个资源的进程才能占有这个资源，而一旦fork之后就要重新来过了）。一旦其中一个进程尝试写入某个内存页，就会触发一个保护故障（缺页异常），此时会陷入内核。内核将拦截写入，并为尝试写入的进程创建这个页面的一个新副本，恢复这个页面的可写权限，然后重新执行这个写操作，这时就可以正常执行了。
>
> 内核会保留每个内存页面的引用数。每次复制某个页面后，该页面的引用数减少1，如果该页面只有一个引用，就可以跳过分配，直接修改。
>
> 这种分配过程对于进程来说是透明的，能够确保一个进程的内存更改在另一个进程中不可见。

### COW的优缺点

> 优点：减少不必要的资源分配，节省宝贵的物理资源
>
> 缺点：如果在子进程存在期间发生了大量写操作，那么会频繁地发成页面错误，不断陷入内核，复制页面。这反而会降低效率

### 进程的状态

> ![img_oprSys_1](.\images\img_oprSys_1.png)
>
> - 就绪：进程已获得除处理器意外的所需资源，等待分配处理器资源
> - 运行：占用处理器资源运行，处于此状态的进程数小于等于CPU数
> - 阻塞：进程等待某种条件，在条件满足之前无法执行

### 进程调度策略有哪些

> ##### 批处理系统：
>
> **先来先服务** first-come first-servered（FCFS）
>
> > 按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定
>
> **最短作业优先** shortest job first （SJF）
>
> > 按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题
>
> **最短剩余时间优先** shortest remaining time next（SRTN）
>
> > 按剩余运行时间的顺序进行调度。（最短作业优先的抢占式版本）。吞吐量高，开销可能较大，提供好的响应时间，可能导致饥饿问题，对长进程不利
>
> **最高响应比优先** Highest Response Ratio Next （HRRN）
>
> > 响应比=1+等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好地平衡了长短进程。非抢占式，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题
>
> 
>
> ##### 交互式系统：
>
> 交互式系统有大量的用户交互操作，在该系统中调度算法的目的时快速地进行响应
>
> **时间片轮转**
>
> > 将所有就绪进程按照FCFS的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为段进程提供好的响应时间。若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证
>
> **优先级调度算法**
>
> > 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级
>
> **多级反馈队列调度算法**
>
> > 设置多个就绪队列123，优先级递减，时间片递增。只有等到优先级更高的队列时才会调度当前队列中的进程。如果进程用完了当前队列的时间片，该进程还未执行完，则会被移到下一队列。抢占式（时间片用完时）开销可能较大，对IO型进程有利，可能会出现饥饿问题。

### 什么叫优先级反转，怎么解决

> 高优先级的进程等待被一个低优先级进程占用资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程限制性。
>
> 具体描述：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的进程一直被挂起（由于资源被抢占，处于阻塞状态），直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级进程在中等优先级进程之后执行。
>
> **解决方案**：
>
> - 优先级天花板（priority ceiling）：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高级，这个优先级称为该资源的优先级天花板。
> - 优先级继承（priority inheritance）：当任务A申请共享资源S时，如果S正在被任务C占用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的优先级。

### 进程的异常控制流：陷阱、中断、异常和信号

> **陷阱**：陷阱是有意造成的”异常“，是执行一条指令的结果。陷阱是同步的，主要作用是实现系统调用。比如，进程可以执行`syscall n`指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，陷入到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行下一条指令。
>
> **中断**：中段由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括I/O设备发出的I/O中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。
>
> **异常**：异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而发生的错误情况，比如触发异常、缺页异常等。
>
> **信号**：信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来通知进车给发生了某种系统事件。

### 什么是死锁

> 在两个或者多个并发进程中，每个进程持有某种资源而又等待其他进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程发生了死锁（deadlock）。

### 死锁产生的必要条件

> - **互斥**：一个资源一次只能被一个进程使用
> - **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其他进程占用的资源
> - **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放
> - **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源

### 死锁的处理方法

> **鸵鸟策略**：
>
> > 什么都不做，因为要解决这个问题代价很大。适用于发生死锁时不会对用户造成多大影响或者发生死锁的概率很低。
>
> **死锁预防**：
>
> > 基本思想是破坏形成死锁的四个必要条件：
> >
> > - **破坏互斥条件**：允许某些资源同时被多个进程访问。但是有些资源本身不具备这种属性
> > - 破坏占有并等待条件：
> >   - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）
> >   - 只允许进程在没有占有资源的时候才能申请资源（申请资源前需要先释放占有的资源）
> >   - 缺点：很多时候无法预知一个进程所需的全部资源；同时会降低资源利用率，降低系统的并发性
> > - **破坏非抢占条件**：允许进程强行抢占被其他进程占有的资源。会降低系统性能
> > - **破坏循环等待条件**：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即占有了大号资源后不能申请小号资源。怎么编号是个问题
>
> **死锁避免**：
>
> > 动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。
> >
> > **银行家算法**：
> >
> > > **设计的数据结构：**
> > >
> > > 1. 可用资源向量available，它记录系统中各类资源的当前可利用数目
> > > 2. 最大需求矩阵max，它记录每个进程对各类资源的最大需求量
> > > 3. 分配矩阵allocation，它记录每个进程对各类资源当前的占有量
> > > 4. 需求矩阵need，它记录每个进程对各类资源还需要的数目，等于最大需求矩阵与分配矩阵的差
> > > 5. 请求向量request，它记录某个进程当前对各类资源的申请量，是银行家算法的入口参数
> > >
> > > **算法描述（设进程P向系统提出request资源需求）：**
> > >
> > > 1. 若request>need，则进程P出错
> > > 2. 若request>available，则进程P阻塞
> > > 3. 系统试着把资源分配给进程P，并对数据结构做一下修改：
> > >    1. available-request
> > >    2. allocation+request
> > >    3. need-request
> > > 4. 系统执行安全性检测子算法，以判断试分配后系统状态是否安全
> > > 5. 若第4步返回true，即安全，则完成本次分配
> > > 6. 否则，撤销此次试分配，进程P阻塞
> > >
> > > **安全子算法：**
> > >
> > > 1. 对于needs数组，遍历该数组，直到找到need<available
> > > 2. 找到need<available之后，收回allocation，并移除need
> > > 3. 重复此过程直至needs为空，返回true
> > > 4. 若一次遍历之后找不到need<available，则返回false
>
> **死锁解除**：
>
> > **死锁检测**：检测有向图是否存在环，或者使用类似于死锁避免的检测算法
> >
> > **死锁解除的方法**
> >
> > 1. 抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长期挂起而处于饥饿状态
> > 2. 回滚：让某些进程回退到足以解除死锁的地步，进程回退时资源释放资源。要求系统保持进程的历史信息，设置还原点
> > 3. 杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行

### 锁的实现

> **锁是给线程用的！！！**
>
> 每个线程在对资源操作前都尝试先加锁，成功加锁才能操作，操作结束解锁。注意：**同一时刻，只能有一个线程持有该锁。**
>
> 首先需要了解如何实现操作的原子性：
>
> **禁止中断**：
>
> > 是指在计算机系统中暂时关闭中断的操作。中断允许计算机在运行过程中暂停当前的任务，处理某个时间或服务请求，然后再返回原来的任务。禁止中断的操作可以阻止中断被响应，确保在一段时间内，CPU不会被中断处理程序中断，从而保持对某些关键操作的独占执行。
> >
> > 缺点：
> >
> > 1. 给用户禁止中断的权利很危险，如果用户进程死循环，操作系统可能永远无法获取控制权
> > 2. 只适用于单CPU的场景，其他CPU上运行的线程依然可以访问临界资源，因为不同CPU有自己的时钟中断器
> > 3. 关中断可能造成某些中断信号丢失，比如磁盘读取完成
> > 4. 效率很低，屏蔽中断的指令执行起来比其他指令慢
>
> **TSL指令**：
>
> > 锁住内存总线，使得一个进程使用内存时另一个进程不能访问内存，即使是另一个CPU也不能访问，这种做法只是弥补了“禁止中断”在多CPU下的问题。
>
> 接下来了解锁的实现：
>
> 获取并设置锁需要是一个原子操作，可以通过TSL、TAS（Test And Set）、CAS（Compare And Swap）或者LL/SC（Load-Link/Store-Conditional）等硬件级别的原子操作指令实现。
>
> **忙等待**：是一种同步机制，通常用于多线程或多进程并发控制中。在忙等待中，线程或进程在未能获取所需资源时，会以循环的方式不断检查资源是否可用，而不是立即放弃CPU控制权或进入休眠状态。
>
> **互斥锁Mutex**
>
> > 当一个线程访问其他线程持有的锁时，会被OS调度为阻塞状态（休眠），直到锁被释放，再唤醒一个休眠的线程。
> >
> > 互斥锁的开销主要体现在线程的重新调度和上下文切换上，获取锁的开销是比较大的。
>
> **自旋锁Spinlock**
>
> > 当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对，不断循环尝试获取锁，直到获取成功。自旋锁的优点是避免了操作系统重新调度和上下文切换的开销，所以非常有效，操作系统内核经常使用自旋锁。
>
> |          | Spinlock                                                     | Mutex                                      |
> | -------- | ------------------------------------------------------------ | ------------------------------------------ |
> | 机制     | 不断循环尝试获取锁，需要配合抢占式调度器（能够发生上下文切换） | 如果获取不到锁就休眠，直到锁被释放后再唤醒 |
> | 实现层面 | 用户进程和操作系统均可实现                                   | 操作系统提供系统调用，因为需要调度         |
> | 适用场景 | 线程持有锁的时间短                                           | 线程持有锁的时间长                         |
> | 缺点     | 获取不到锁时空转，浪费CPU                                    | 重新调度、上下文切换的开销                 |
>
> **需要注意的是**：这里的实现层面存疑（个人观点），你Spinlock需要原子操作也需要系统调用吧。原文：https://imageslr.com/2020/locks
>
> **自适应锁Adaptive Mutex**
>
> > 先执行 spinlock 操作，不断持续尝试获取锁；如果尝试多次还是获取不到，就执行 mutex 操作，让线程进入睡眠。还有的叫法是两阶段锁（Two-Phase Lock）、混合锁（Hybrid Mutex）。
> >
> > glibc 的 futex 就是用这种机制（linux）。





## 内存

### 内存管理方式

> **连续分配管理**：单一连续分配、固定分区分配、动态分区分配、动态重定位分区分配
>
> **非连续分段管理（离散分配管理）**：分页存储管理方式（基本单位是页Page）、分段存储管理方式（基本单位是段Segment）

### 连续分配管理

> 连续分配管理方式允许一个用户程序分配一个连续的内存空间。
>
> - **单一连续分配**：多用于单用户单任务的操作系统中，是一种简单的存储管理方式。单一连续分配中，会将存储空间分配为**系统区**和**用户区**。系统区存放系统进程，用户区存放用户进程，这样的管理避免用户进程影响到系统进程。这种分配方式中，比如[0, a]的地址空间存放系统区，[a+1, n]的地址空间都存放用户区。
> - **固定分区分配**：是一种最简单的可运行多道程序的存储管理方式。固定分区分配首先要划分分区，之后进行内存分配。
>   - 内存分区分为**分区大小相等**和**分区大小不等**两种。
>     - 分区大小相等的情况下，如果进程大小不相等容易造成内存浪费或者内存不够进程无法运行的问题，所以通常用于进程内存大小相等的情况。
>     - 分区大小不等的情况下，就是根据常用的大小（较多的小分区，适量的中分区，较小的大分区）进行分区，这样就可以更好地利用内存空间，但是这样的方式需要维护一个分区使用表。内存分配要维护一张分区使用表，通常按照进程大小进行排序。每次在进行内存分配的时候，要查看哪些分区能够容纳该进程。
> - **动态分区分配**：根据进程的需要，动态地分配内存空间。这样的分配方式涉及到分区中的数据结构、分区分配算法以及分区的分配和挥手操作三个问题。
>   - **分区数据结构**：主要分为空闲分区表和空闲分区链两种。
>     - 空闲分区表：维护空闲分区的序号、空闲分区的起始地址以及空闲分区的大小数据。
>     - 空闲分区链：相当于一个双向链表维护空闲分区，为了方便检索，在分区尾部设置一个分区的状态位以及分区大小。
>   - **分区分配算法**：
>     - **首次适应算法（First Fit）**：利用空闲分区链实现，将空闲分区按照**地址递增**进行排序，然后根据进程的大小从链首查找空闲分区链，第一个能够适应的就分配。
>     - **循环首次适应算法（Next Fit）**：与首次适应算法不同的是，该算法从上一个找到的空闲分区向下找，直到找到一个能够使用的分区，之后动态地分配内存（会导致后续大空闲分区变少）。
>     - **最佳适应算法（Best Fit）**：将空闲分区链按照**大小**进行排序，找到第一个适应的空闲分区即可（最大限度利用空闲分区）。
>     - **最坏适应算法（Worst Fit）**：与最佳适应相反，排序之后每次挑最大的分区使用，对中小作业有利，不易产生碎片。
>     - **快速适应算法（Quick Fit）**：根据大小将空闲分区进行分类，维护多个空闲分区链，这样的好处是可以加快检索，相比一条链能够更快地检索目标进程。
>   - **分区分配和回收**：主要操作是内存的分配和回收。内存分配中，若空闲分区内存大小-用户进程内存大小<=预设不可切分内存大小，则进行内存的分配；否则将剩余的内存空间放到空闲内存链中，继续下次的使用（这里指分配完用户进程之后）。内存回收，主要看是否和空闲分区相邻，如果相邻就直接合并，否则建立新的表项，维护会收取的内存起始地址和大小。
> - **动态重定位分区分配**：在连续分配方式中，必须把系统进程或者用户进程装入一个连续的内存空间中。这个时候可能会因为程序的大小与分区的大小不一致的问题产生内存碎片。这个时候我们要想插入新的进程，即使碎片空间综合支持进程，也无法再分配空间，所以我们要把内存空间进行一个整理。
>   - **整理内存地址**：是将程序的内存地址整理成在物理上相邻的状态。程序使用的地址在分区装载之后仍然是相对地址，要想将相对地址转换为相邻的物理地址，必然会影响到程序的执行。为了不影响程序的执行，需要在硬件上提供对程序的内存地址转换支持，于是引入重定位寄存器，用它来存放程序在内存中的起始地址。

### 非连续分配管理

> 非连续分配管理方式允许将一个程序分散地装入不相邻的内存分区。根据内存分区的大小分为**分页式存储管理方式**和**分段式存储管理方式**。
>
> - **页存储**：页存储首先需要将一个进程的逻辑内存空间划分为多个内存大小相等的页，然后将物理内存空间划分为相等的大小个数的物理块（**页框**Frame）。分配的时候将多个页面放入多个不相邻的物理块中。这样的划分之后，通常进程的最后一页存不满，会产生内存碎片--“页内碎片”。
>
>   - **需要注意的是**：
>     - 一般地，统一操作系统的所有进程的页面大小一样。
>   - **页面大小**：页面大小的选的需要适当。如果过小，可以减少页内碎片的产生，但是需要更大的页表，而且页面切换更频繁。如果太大就会产生较大的内存碎片。所以大小的选择应该适中，通常为2的整数次幂，范围为[512B, 8KB]。
>   - **页表**：页表主要保存进程占用的页数，同时存储逻辑内存空间页到物理内存块的映射。
>   - **地址转换**：页表要存储地址映射，那么首先得有一个地址变换机构。
>     - 基本地址变换机构：主要用来建立逻辑地址到物理内存空间地址的映射。
>       - 传统系统中，主要使用寄存器来存放页表（寄存器速度快，有利于变换地址），那么每一个页表都需要寄存器来存放，成本过高。进程数量过多的情况下，页表项总数可达几千甚至几十万个，因此页表大多驻留在内存中。在系统中只设置一个页表寄存器，在其中存放页表在内存的起始地址和页表的长度。平时，进程未执行时，将页表的起始地址和页表长度存放在PCB（Process Control Block，进程控制块）中，之后在进程运行的时候再将数据读取到PTR（Page-Table Register，页表寄存器）。
>       - 读取数据的时候，地址转换机构会将相对地址转换为页号以及页内地址两部分，之后根据页号检索页表。检索之前会将页号和页表长度进行比较，如果页号大于或等于页表长度，则说明出现了访问越界，会出现越界中断。否则物理地址=页表起始地址 + 页号 * 页表长度 + 页内地址。
>     - 具有块表的地址转换机构：
>       - 由于页表是存放在内存中的，这使CPU在每存取一个数据时，都要访问两次内存。第一次是访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量拼接，得到物理地址。第二次访问内存时，才是从第一次所得地址中获得所需数据（或向此地址中写入数据）。
>       - 为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的特殊告诉缓冲寄存器，又称为“联想寄存器”（Associative Memory），或称为“快表”，用以存放当前访问的页表项。此时的地址变换过程是：在CPU给出有效地址后，由地址变换机构自动地将页号送入快表中，并将此页号与快表中的所有页号进行比较，若其中有与此相匹配的页号，则表示要访问的页表项在快表中。于是可以直接从快表中读取该页所对应的物理块号，并送到物理地址寄存器中。否则，还需要再访问内存中的页表，找到后再把读出的物理块号送到物理地址寄存器。同时，再将此页表项存入快表的一个寄存器单元中。亦即，重新修改快表。如果联想寄存器已满，则OS必须找到一个老的且已被认为不再需要的页表项，将它换出。
>
>   对于32位操作系统，使用两级页表结构是合适的。但是对于64位操作系统，建议采用多级页表。
>
> - **段存储**：引入分段存储管理方式，主要是为了满足用户和程序员的下属一些列需求。
>
>   - **方便编程**：通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从0开始编址，并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名（段号）和段内偏移量（段内地址）决定的。
>   - **信息共享**：在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程和函数。分页系统中的“页”只是存放信息的物理单位（块），并无完整的意义，不便于共享。然而段确实信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用户程序分段的组织方式相适应。
>   - **信息保护**：信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地实现信息保护功能。
>   - **动态增长**：在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又无法确切地直到数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。
>   - **动态链接**：动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段（目标程序）调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。
>
>   **分段**
>
>   在分段存储管理方式中，作业的地址空间被划分为托干个段，每个段定义了一组逻辑信息。例如，有主程序段MAIN、子程序段X、数据段D及栈段S等。每个段都有自己的名字，为了实现简单起见，通常可用一个段号来代替段名，每个段都从0开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组长度决定，因而各段长度不等。整个作业的地址空间是分成多个段的，因而是二维的，亦即，其逻辑地址由段号（段名）和段内地址所组成。
>
>   **段表**
>
>   在分段式存储管理系统中，为每个分段分配一个连续的分区，而进程中的各个段可以离散地移入内存中不同的分区中。为使程序能正常运行，即能从物理内存中找出每个逻辑段所对应的位置，应像分页系统那样，在系统中为每个进程建立一张映射表，即“段表”。每个段在表中占有一个表项，其中记录了该段在内存中的起始地址（又称为“基址”）和段的长度。段表可以存放在一组寄存器中，这样有利于提高地址转换速度，但更常见的是将段表放在内存中。
>
>   **地址变换**
>
>   为了实现从进程的逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表基址和段表长度TL。在进行地址交换时，系统将逻辑地址中的段号S与段表长度TL进行比较。若S>TL，表示段号太大，是访问越界，会产生访问越界中断信号；若未越界，则根据段表的基址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址，然后，再检查段内地址d是否超过该段的段长SL。若超多，即d>SL，同样发出越界中断信号；若未越界，则将该段的基址d与段内地址相加，即可得到要访问的内存物理地址。
>
> - 分页和分段的主要区别
>
>   - 页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外碎片，提高内存的利用率。分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。
>   - 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，取决于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
>   - 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间是二维的，程序员在标识一个地址时，既需要给出段名，又需要给出段内地址。
>
> - 信息共享
>
>   - 分段系统的一个突出优点，是易于实现段的共享，即允许若干个进程共享一个或多个分段，且对段的保护也十分简单易行。在分页系统中，虽然也能实现程序和数据的共享，但远不如分段系统来得方便。我们通过一个例子来说明这个问题。例如，有一个多用户系统，可同时接纳 40 个用户，他们都执行一个文本编辑程序(Text Editor)。如果文本编辑程序有 160 KB 的代码和另外 40 KB 的数据区，则总共需有 8 MB 的内存空间来支持 40 个用户。如果 160 KB 的代码是可重入的(Reentrant)，则无论是在分页系统还是在分段系统中，该代码都能被共享，在内存中只需保留一份文本编辑程序的副本，此时所需的内存空间仅为1760 KB(40×40+160)，而不是 8000 KB。假定每个页面的大小为 4 KB，那么，160 KB 的代码将占用 40 个页面，数据区占 10 个页面。为实现代码的共享，应在每个进程的页表中都建立 40 个页表项，它们的物理块号都是 21#～60#。在每个进程的页表中，还须为自己的数据区建立页表项，它们的物理块号分别是 61#～70#、71#～80#、81#～90#，…，等等。
>   - 在分段系统中，实现共享则容易得多，只需在每个进程的段表中为文本编辑程序设置一个段表项。

### 段页式存储管理方式

> 前面所介绍的分页和分段存储管理方式都各有其优缺点。分页系统能有效地提高内存利用率，而分段系统则能很好地满足用户需要。如果能对两种存储管理方式“各取所长”，则可以将两者结合成一种新的存储管理方式系统。这种新系统既具有分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点，又能像分页系统那样很好地解决内存的外部碎片问题，以及可为各个分段离散地分配内存等问题。把这种结合起来形成的新系统称为“段页式系统”。
>
> 段页式系统的基本原理，是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。
>
> 在段页式系统中，其地址结构由段号、段内页号及页内地址三部分所组成。
>
> 在段页式系统中，为了便于实现地址变换，须配置一个段表寄存器，其中存放段表始址和段表长 TL。进行地址变换时，首先利用段号 S，将它与段表长 TL 进行比较。若 S<TL，表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址，并利用逻辑地址中的段内页号 P 来获得对应页的页表项位置，从中读出该页所在的物理块号 b，再利用块号 b 和页内地址来构成物理地址。
>
> 在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中，取出指令或数据。
>
> 显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址；若未找到匹配表项，则仍须再三次访问内存。由于它的基本原理与分页及分段的情况相似，故在此不再赘述。

### 页面置换算法

> **最佳页面置换算法OPT**：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略
>
> **先进先出FIFO**：置换在内存中驻留时间最长的页面。可能将哪些经常被访问的页面也被换出，从而使缺页率升高
>
> **第二次机会算法SCR**：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0
>
> **时钟算法Clock**：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销
>
> **最近未使用算法NRU**：检查访问位R，修改位M，优先置换R=M=0，其次是R=0，M=1
>
> **最近最少使用算法LRU**：置换出未使用时间最长的一页。实现方式：维护时间戳或者一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的
>
> **最不经常使用算法LFU**：置换出访问次数最少的页面
>
> **局部性原理**：
>
> - 时间上：最近被访问的页面在不久的将来还会被访问
> - 空间上：内存中被访问的页周围的页也很可能被访问
>
> **颠簸现象**：
>
> > 本质上是指频繁的页面调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断发生缺页中断，导致整个系统的效率急剧下降。解决策略：
> >
> > - 修改页面置换算法
> > - 降低同时运行的程序的数量
> > - 终止该进程或增加物理内存容量

### 虚拟地址空间

> **虚拟地址空间的组成部分**：
>
> 整体上，操作系统将每个进程的虚拟地址空间划分成两个部分：内核空间和用户空间。内核空间存放的是内核代码和数据，用户空间存放的是用户程序的代码和数据。在32位操作系统中，一般将最高的1G字节作为内核空间，而将较低的3G字节作为用户空间。
>
> 进程运行在内核空间时，处于内核态，此时可以执行任何特权指令。每个进程的内核空间都是相同的，用户代码无法访问内核空间。
>
> 虚拟空间的完整组成（从上往下依次是）：
>
> ![img_oprSys_2](.\images\img_oprSys_2.jpg)
>
> - 内核虚拟内存：所有进程共享内核的代码和全局数据结构，独享与进程相关的数据结构，Linux会将内核虚拟内存的共享区域映射到被所有进程共享的物理页面上
> - 用户栈：从高地址向低地址增长
> - 共享库：动态链接阶段
> - 运行时堆：从低地址向高地址增长
> - 程序代码和数据：从可执行文件中加载（代码段、数据段、BSS段）
>
> **栈**：
>
> 用户栈其实就是函数调用栈，作用主要是：
>
> - 保存函数的局部变量
> - 保存某些寄存器的值
> - 向被调用函数传递参数
> - 返回函数的返回值
> - 保存函数的返回地址
>
> 每个函数在执行过程中都需要使用一块栈内存用来保存上述这些值，这块栈内存为该函数的栈帧（stack frame）。栈的增长和收缩由编译器插入的代码自动完成，随着函数的调用而分配，随函数的返回而自动释放。程序员无需关心，这一点与堆不同。
>
> **堆**：
>
> 栈内存的分配实现确定其大小，而堆内存允许程序在运行时动态申请某个大小的内存空间。申请的内存在函数退出后依然保留，需要手动释放。C语言中的malloc/free就是从堆中分配/释放内存，操作系统通过一个记录空闲内存地址的链表来管理堆内存。
>
> 如果反复向操作系统申请堆内存而不释放，会导致内存泄漏。在C/C++中，必须由程序员手动释放堆内存。而Java/Golang中有垃圾回收期，会定期主动回收内存。但是即使有垃圾回收器，也有内存泄漏的风险，比如长期持有某个大对象的引用。
>
> **堆和栈的区别**：
>
> 1. 增长方向：栈向低地址增长，堆向高地址增长
> 2. 申请回收：栈自动分配和回收，堆需要手动申请和释放
> 3. 生命周期：栈的数据仅存在于函数运行过程中，堆的数据只要不释放就一直存在
> 4. 连续分配：栈是连续分配的；堆是不连续的，容易产生内存碎片
> 5. 空间大小：栈的大小是有限的，而堆的空间较大，受限于系统中有效的虚拟内存

### malloc和free的实现

> malloc使用链表管理内存块。malloc有多种实现方式，详见连续分配管理和非连续分配管理。
>
> malloc分配的空间中包含一个首部来记录控制信息，因此它分配的空间要比实际需要的空间大一些。这个首部对用户而言是透明的，malloc返回的是紧跟在首部后面的地址，即可用空间的起始地址。
>
> malloc分配的函数应该是字节对齐的。在32位模式中，malloc返回的块总是8的倍数。在64位模式中，该地址总是16的倍数。最简单的方式是先让堆的起始位置字节对齐，然后始终分配字节大小倍数的内存。
>
> malloc分配几种固定大小的内存块，可以减少外部碎片，简化对齐实现，降低管理成本。
>
> free只需要传递一个指针就可以释放内存，空间大小可以从首部读取。
>
> 首部结构体：
>
> ```c++
> struct mem_control_block{
> 	int is_available; // 实际是否可用（如果还没被分配出去，就是1）
> 	int size;		  // 实际空间的大小
> };
> ```

### 大端法、小端法

> 计算机最小的可寻址的内存单位是字节。按有效字节在内存地址中从小到大的存储顺序，可以分为大端法和小端法。计算机在内存中存放数据的顺序都是从低到高的。大端法从高位到低位存储，小端法从低位到高位存储。比如某个 int 型整数的值为 `0x01234567`（**左边是高位，右边是低位**），存储在 `0x100`~`0x103` 的内存地址上。大端法和小端法的字节顺序如下所示：
>
> ![img_oprSys_3](.\images\img_oprSys_3.jpg)
>
> 可以通过按内存地址顺序从低到高输出一个变量（借助char*）的全部字节的方式来区分是大端法还是小端法。
>
> ```c++
> int main(){
> 	int a = 0x1234;
> 	char *p = &a;
> 	printf("%02x\n", *p);
> 	printf("%02x\n", *(p + 1));
> 	printf("%02x\n", *(p + 2));
> 	return 0;
> }
> ```
>
> 判断以上的输出（大端小端都要）：
>
> 特别需要注意的是，int是32位，所以完整的数据应该是0x00001234。
>
> 大端法：00 00 12
>
> 小端法：34 12 00

### 缓冲区溢出问题

> C语言使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C对于数组引用不进行任何边界检查，因此对越界的数组元素的写操作会破坏存储在栈中的状态信息，这种现象称为缓冲区溢出。
>
> ![img_oprSys_4](.\images\img_oprSys_4.jpg)
>
> 缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。
>
> ![img_oprSys_5](.\images\img_oprSys_5.jpg)
>
> 防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。
>
> > 1. **随机化**：使用缓冲区溢出进行攻击，需要直到攻击代码的地址。因此常见的方法有：
> >
> >    1. 栈随机化：程序开始时在栈上分配一段随机大小的空间
> >    2. 地址空间布局随机化（Address-Space Layout Randomization，ASLR）：每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域
> >
> >    但是攻击者依然可以使用蛮力克服随机化，这种方式称为“空操作雪橇（nop sled）”，即在实际的攻击代码前插入很长的一段nop指令序列，执行这条指令只会移动到下一条指令。因此，只要攻击者能够猜中这段序列的某个地址，程序就会最终经过这段序列，到达攻击代码。
> >
> >    因此栈随机化和ASLR只能增加攻击一个系统的难度，不能保证完全安全。
> >
> > 2. **栈保护**：在发生缓冲区溢出、造成二年和有害效果之前，尝试检测到它。常见的栈破坏检测方法是栈保护机制：在每个函数的栈帧的局部变量和栈状态之间存储一个随机产生的特殊的值，称为金丝雀值（canary）。在回复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。
> >
> >    ![img_oprSys_6](.\images\img_oprSys_6.jpg)
> >
> > 3. **限制可执行代码区域**：内存页的访问形式有三种：可读、可写、可执行。只有编译器产生的那部分代码所处的内存才是可执行的，其他页应当限制为只允许读和写。以前x86将读和执行视为一个标志位，可读就可执行，为了限制某些页可读但不可执行，往往会带来严重的性能损失。现在新的处理器在硬件上引入新的位，将读和执行分开，由硬件来检查页是否可执行，效率是没有损失。





## I/O多路复用

### 什么是I/O多路复用，怎么实现

> I/O多路复用（I/O Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。
>
> **从阻塞I/O到I/O多路复用：**
>
> > - 阻塞I/O，是指进程发起调用后，会被挂起（阻塞），直到收到数据再返回。如果调用一直不返回，进程就会一直被挂起。因此，当使用阻塞I/O时，需要使用多线程来处理多个文件描述符。
> > - 多线程切换有一定的开销，因此引入非阻塞I/O。非阻塞I/O不会将进程挂起，调用时会立即返回成功或错误，因此可以在一个线程里轮询多个文件描述符是否就绪。
> > - 但是非阻塞I/O的缺点是：每次发起系统调用，只能检查一个文件描述符是否就绪，当文件描述符很多时，系统调用的成本很高。
> > - 因此引入多路复用，可以通过一次系统调用，检查多个文件描述符的状态。这是I/O多路复用的主要有点，相比于非阻塞I/O，在文件描述符较多的场景下，避免了频繁的用户态和内核态的切换，减少了系统调用的开销。
> > - I/O多路复用相当于将遍历所有文件描述符、通过非阻塞I/O查看其是否就绪的过程从用户线程移到了内核中，由内核来负责轮询。
>
> 进程可以通过select、poll、epoll发起I/O多路复用的系统调用，这些系统调用都是同步阻塞的：如果传入的多个文件描述符中，有描述符就绪，则返回就绪的描述符；否则就阻塞调用进程，直到某个描述符准备就绪，或者阻塞时长超过设置的timeout后，再返回。I/O多路复用内部使用非阻塞I/O检查每个描述符的就绪状态。
>
> 如果timeout参数设置为Null，会无限阻塞直到某个描述符准备就绪；如果timeout参数设为0，会立即返回，不阻塞。

### I/O多路复用之select

> ```c++
> int select(int nfds,  fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout);
> ```
>
> readfds、writefds、errorfds是三个文件描述符的集合。select会遍历每个集合前nfds个描述符，分别找到可以读取、可以写入、发生错误的描述符，统称为”就绪“的描述符。然后找到的子集替换参数里的集合，返回所有就绪描述符的总数。
>
> ```c++
> // talk is cheap, show me the code
> #include <stdio.h>
> #include <stdlib.h>
> #include <sys/time.h>
> #include <sys/types.h>
> #include <unistd.h>
> 
> int main(void) {
>     // open and set up a bunch of sockets (not shown)
>     // main loop
>     while(1){
>         // initialize the fd_set to all zero
>         fd_set readFDs;
>         FD_ZERO(readFDs);
>         
>         // now set the bits for the descriptors
>         // this server is interested in
>         // (for simplicity, all of them from min to max)
>         int fd;
>         for(fd = minFD; fd < maxFD; ++fd){
>             FD_SET(fd, &readFDs);
>         }
>         
>         // do the select
>         int rc = select(maxFD+1, &readFDs, NULL, NULL, NULL);
>         
>         // check which actually have data using FD_ISSET()
>         for(fd = minFD; fd < maxFD; ++fd){
>             if(FD_ISSET(fd, &readFDs)){
>                 processFD(fd);
>             }
>         }
>     }
> }
> ```
>
> **缺点**：
>
> 1. 性能开销大，调用select时会陷入内核，这时需要将参数中的fd_set从用户空间拷贝到内核空间
> 2. 内核需要遍历传递进来的所有fd_set的每一位，不管它们是否就绪
> 3. 同时能够监听的fd数量太少。受限于sizeof(fd_set)的大小，在编译内核时就确定了且无法更改。一般是1024，不同的操作系统不相同。

### I/O多路复用之poll

> ```c++
> int poll(struct pollfd *fds, nfds_t nfds, int timeout);
> ```
>
> poll和select几乎没有区别。poll在用户态通过数组方式传递文件描述符，在内核会转为链表方式存储，没有最大数量的限制。
>
> 其中`fds`是一个`pollfd`结构体类型的数组，调用`poll()`时必须通过`nfds`指出数组`fds`的大小，即文件描述符的数量。
>
> 从性能开销上看，poll和select差别不大。

### I/O多路复用之epoll

> epoll是对select和poll的改进，避免了”性能开销大“和”文件描述符数量少“两个缺点。
>
> 简而言之，epoll有以下几个特点：
>
> - 使用红黑树存储文件描述符集合
> - 使用队列存储就绪的文件描述符
> - 每个文件描述符只需在添加时传入一次，通过事件更改文件描述符的状态
>
> select和poll都只使用一个函数，而epoll模型使用三个函数：`epoll_create`、`epoll_ctl`和`epoll_wait`。
>
> **epoll_create**
>
> > ```c++
> > int epoll_create(int size);
> > ```
> >
> > `epoll_create`会创建一个`epoll`实例，同时返回一个引用该实例的文件描述符。
> >
> > 返回的文件描述符仅仅指向相应的`epoll`实例，并不代表真是的磁盘文件节点。其他API如`epoll_ctl`、`epoll_wait`会使用这个文件描述符来操作相应的`epoll`实例。
> >
> > 当创建好`epoll`句柄后，它会占用一个fd值，在linux下查看`/proc/进程id/fd/`，就能看到这个fd。所以在使用`epoll`后，必须调用`close(epfd)`关闭相应的文件描述符，否则可能导致fd被耗尽。当指向同一个`epoll`实例的所有文件描述符都被关闭后，操作系统会销毁这个`epoll`实例。
> >
> > `epoll`实例内部存储：
> >
> > - 监听列表：所有要监听的文件描述符，使用红黑树
> > - 就绪列表：所有就绪的文件描述符，使用链表
>
> **epoll_ctl**
>
> > ```c++
> > int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
> > ```
> >
> > `epoll_ctl`会监听文件描述符fd上发生的event事件。
> >
> > 参数说明：
> >
> > - `epfd`即`epoll_create`返回的文件描述符，指向一个`epoll`实例
> > - fd表示要监听的目标文件描述符
> > - event表示要监听的事件（可读、可写、发送错误...）
> > - op表示要对fd执行的操作，有以下几种：
> >   - `EPOLL_CTL_ADD`：为fd添加一个监听事件event
> >   - `EPOLL_CTL_MOD`：改变fd的监听事件，变量event本身没变，但是改变了其内部字段的值
> >   - `EPOLL_CTL_DEL`：删除fd的所有监听事件，这种情况下event参数无效
> >
> > 返回值0或-1，表示上述操作成功与否。
> >
> > `epoll_ctl`会将文件描述符fd添加到`epoll`实例的监听列表里，同时为fd设置一个回调函数，并监听事件event。当fd发生相应事件时，会调用回调函数，将fd添加到epoll实例的就绪队列上。
>
> **epoll_wait**
>
> > ```c++
> > int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
> > ```
> >
> > 这是epoll模型的主要函数，功能相当于select。
> >
> > 参数说明：
> >
> > - epfd即epoll_create返回的文件描述符，指向一个epoll实例
> > - events是一个数组，保存就绪状态的文件描述符，其空间由调用者负责申请
> > - maxevents指定events的大小
> > - timeout类似于select中的timeout。如果没有文件描述符就绪，即就绪队列为空，则epoll_wait会阻塞timeout毫秒。如果timeout设为-1，则epoll_wait会一直阻塞直到由文件描述符就绪。如果timeout设为0，则epoll_wait会立即返回。
> >
> > 返回值表示events中存储的就绪描述符个数，最大不超过maxevents。
>
> **epoll的优点**
>
> > select使用整形数组存储文件描述符集合，而epoll使用红黑树存储
> >
> > epoll_ctl为每个文件描述符指定了回调函数，并在就绪时将其加入到就绪列表，因此epoll不需要像select那样遍历每个文件描述符，只需要判断就绪列表是否为空即可。这样，在没有描述符就绪时，epoll能更早地让出系统资源
> >
> > 每次调用select时否需要向内核拷贝所有需要监听的描述符集合，而epoll对于每个描述符，只需要在epoll_ctl传第一次，之后epoll_wait不需要再次传递，这样也大大提高了效率。
>
> - **select**：调用开销大（需要复制集合），集合大小有限制，需要遍历整个集合找到就绪的描述符，只支持水平触发
> - **poll**：poll采用数组的方式存储文件描述符，没有最大存储数量的限制，其他方面和select没有区别
> - **epoll**：调用开销小（不需要复制），集合大小无限制，采用回调机制，不需要遍历整个集合，支持边缘触发
>
> select和poll都是在用户态维护文件描述符集合，因此每次都需要将完整集合传给内核；epoll由操作系统在内核态维护文件描述符集合，因此只需要在创建的时候传入文件描述符。
>
> 当连接数较多且有很多不活跃连接时，epoll的效率比其他两者高很多。当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能低于其他两者。

### 水平触发和边缘触发

> `select`支支持水平出发，`epoll`支持水平出发和边缘出发。
>
> 水平出发（LT，Level Trigger）：当文件描述符就绪时，会出发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。
>
> 边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。
>
> 区别：边缘出发效率更高，减少了事件被重复出发的次数，函数不会返回大量用户程序可能不需要的文件描述符。

### 为什么边缘触发必须使用非阻塞I/O

> - 每次通过read系统调用读取数据时，最多只能读取缓冲区大小的字节数；如果某个文件描述符一次性收到的数据超过了缓冲区的大小，那么需要对其read多次才能全部读取完毕
> - select可以使用阻塞I/O。通过select获取到所有可读的文件描述符后，遍历每个文件描述符，read一次数据，这些文件描述符是可读的，因此即使read是阻塞I/O，也一定可以读到数据，不会一直阻塞下去
> - select采用水平出发模式，因此如果第一次read没有读取完全部数据，那么下次调用select时依然会返回这个文件描述符，可以再次read
> - select也可以使用非阻塞I/O。当遍历某个可读文件描述符时，使用for循环调用read多次，直到读取完所有数据位置（返回EWOULDBLOCK）。这样做会多调用一次read，但可以减少调用select的次数。
> - 如果使用epoll的边缘触发模式，在收到通知时，必须使用非阻塞I/O，并且必须循环调用read或wirte多次，直到返回EWOULDBLOCK为止，然后再调用epoll_wait等待操作系统的下一次通知
> - 如果没有一次性读/写完所有数据，那么在操作系统看来这个文件描述符的状态没有发生改变，将不会再发起通知，调用epoll_wait会使该文件描述符一直等待下去，服务端也会一直等待客户端的响应，业务流程无法走完
> - 这样做的好处是epoll_wait每次都是有效的--保证数据全部读写完毕了，等待下一次通知。在水平触发模式下，如果调用epoll_wait时数据没有读/写完毕，会直接返回，再次通知。因此边缘触发能显著减少事件被触发的次数
> - 为什么epoll的边缘模式不使用非阻塞I/O？很显然，边缘触发模式需要循环读/写一个文件描述符的所有数据。如果使用阻塞I/O，那么一定会在会后一次调用（没有数据可读/可写）时阻塞，导致无法正常结束。





## 磁盘

### 磁盘的结构

> **磁盘**：磁盘的表明有一些磁性物质组成，可以用来记录二进制数据
>
> **磁道**：磁盘的盘面被划分成一个个圈，这样的一个圈就是一个磁道
>
> **扇区**：一个磁道又被划分为一个个扇区，每个扇区就是一个“磁盘块”。各个扇区存放的数据量相同，最内侧磁道上的扇区面积最小，数据密度最大
>
> **盘面**：磁盘有多个盘片摞起来，每个盘片有两个盘面
>
> **柱面**：所有盘面中相对位置相同的磁道组成柱面

### 如何在磁盘中读/写数据

> 需要把磁头移动到想要读/写的扇区所在的磁道，磁盘会转起来，让目标扇区从磁头下面划过，才能完成对扇区的读/写操作

### 磁盘读写时间

> #### 寻找时间（寻道时间）T<sub>s</sub>
>
> 在读/写数据前，将磁头移动到指定磁道所花的时间。
>
> 1. 启动磁头臂是需要时间的。假设耗时为s
> 2. 移动磁头也是需要时间的。假设磁头匀速移动，每跨越一个磁道耗时为m，总共需要跨越n条磁道。
>
> 寻道时间**T<sub>s</sub>=s+m*n**
>
> 现在的硬盘移动一个磁道大约需要0.2ms，磁臂启动时间约为2ms。
>
> #### 延迟时间T<sub>r</sub>
>
> 通过旋转磁盘，使磁头定位到目标扇区所需要的时间。设磁盘转速为r（单位：转/秒，或 转/分）
>
> 则平均所需的延迟时间**T<sub>r</sub>=(1/2)*(1/r) = 1/(2r)**
>
> 1/r就是转一圈需要的时间。找到目标扇区平均需要转半圈，因此再乘以1/2。
>
> 硬盘的典型转速为5400转/分或者7200转/分。
>
> #### 传输时间T<sub>t</sub>
>
> 从磁盘读出或向磁盘写入数据所经历的时间，假设磁盘转速为r，此次读/写的字节数为b，每个磁道上的字节数为N。则：
>
> 传输时间**T<sub>t</sub>=(1/r)*(b/N)=b/(rN)**
>
> 每个磁道要可存N字节的数据，因此b字节的数据需要b/N个磁道才能存储。而读/写一个磁道所需的时间刚好又是转一圈所需要的时间1/r。（为什么刚好是转一圈的时间，不知道啊）
>
> **T=T<sub>s</sub>+T<sub>r</sub>+T<sub>t</sub>**
>
> 操作系统无法影响延迟时间和传输时间，但可以影响寻道时间（通过调度算法）。

### 磁盘调度算法

> **先来先服务算法（FCFS）**：根据进程请求访问磁盘的先后顺序进行调度。
>
> **最短寻找时间优先（SSTF）**：优先处理的磁道是与当前磁头最近的磁道。可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短（贪心，局部最优）。
>
> **扫描算法**（SCAN）：SSTF算法产生饥饿的原因在于，磁头有可能再一个小区域内来回地移动。为了防止这个问题，可以规定，只有磁头移动到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。这就是扫描算法的思想，由于磁头移动的方式很像电梯，因此也叫电梯算法。
>
> **LOOK调度算法**：在电梯调度的基础上，改变了磁头转向的实际。磁头移动方向上已经没有别的请求了，就可以立即改变磁头的移动方向。
>
> **循环扫描算法**（C-SCAN）：只有在磁头朝某个特定方向移动时才处理磁道访问请求，而返回时直接快速移动至起始端而不处理任何请求。
>
> **C-LOOK调度算法**：在LOOK的基础上，改变磁头移动方向的时候，直接返回到最接近边缘且需要访问的磁道上。

